import time

import torch
import argparse
from pathlib import Path
from tqdm import tqdm


def strip_optimizer(input_model='best.pt', out_model='out.pt'):

    # å¤„ç†æ¨¡å‹
    x = torch.load(input_model, map_location=torch.device('cpu'))
    if x.get('ema'):
        x['model'] = x['ema']
    for k in ['optimizer', 'best_fitness', 'ema', 'updates']:
        x[k] = None
    x['epoch'] = -1
    x['model'].half()
    for p in x['model'].parameters():
        p.requires_grad = False

    # ç¡®å®šä¿å­˜è·¯å¾„
    save_path = out_model or input_model
    torch.save(x, save_path)

    # è·å–åŸå§‹æ–‡ä»¶å¤§å°
    orig_size = Path(input_model).stat().st_size / 1e6  # MB
    # è·å–æ–°æ–‡ä»¶å¤§å°
    new_size = Path(save_path).stat().st_size / 1e6

    # æ‰“å°å¯¹æ¯”ç»“æœ
    print(f"å‹ç¼©å®Œæˆ: {orig_size:.1f}MB â†’ {new_size:.1f}MB")
    print(f"ä¿å­˜ä¼˜åŒ–åçš„æ¨¡å‹ {out_model or input_model}, å¤§å°ä¸º: {new_size:.1f} MB")


def strip_optimizer_visualization(input_model='best.pt', out_model='out.pt', progress=False):

    # åŸå§‹æ–‡ä»¶ä¿¡æ¯
    orig_path = Path(input_model)
    orig_size = orig_path.stat().st_size / 1e6  # MB

    # ====================== å¤„ç†é˜¶æ®µ ======================
    def update_pbar(pbar, step, desc):
        if progress and pbar:
            pbar.set_postfix_str(desc)
            pbar.update(step)
        elif not progress:
            print(f"â–¶ {desc}")

    time.sleep(0.0001)  # æ¨¡æ‹Ÿæ“ä½œå»¶è¿Ÿ

    # ä¸»å¤„ç†æµç¨‹
    if progress:
        main_pbar = tqdm(total=3, desc="ğŸ› ï¸ æ¨¡å‹å¤„ç†", unit="step")
    else:
        main_pbar = None

    # 1. åŠ è½½æ¨¡å‹
    x = torch.load(input_model, map_location=torch.device('cpu'))
    update_pbar(main_pbar, 1, "æ¨¡å‹åŠ è½½å®Œæˆ")

    # 2. å¤„ç†EMAæƒé‡
    if x.get('ema'):
        x['model'] = x['ema']
        update_pbar(main_pbar, 1, "EMAæƒé‡å·²åº”ç”¨")
    else:
        update_pbar(main_pbar, 1, "æœªæ£€æµ‹åˆ°EMAæƒé‡")

    # 3. æ¸…ç†å…ƒæ•°æ®
    for k in ['optimizer', 'best_fitness', 'ema', 'updates']:
        x[k] = None
    x['epoch'] = -1
    update_pbar(main_pbar, 1, "å…ƒæ•°æ®æ¸…ç†å®Œæˆ")

    if main_pbar:
        main_pbar.close()

    # ====================== è½¬æ¢é˜¶æ®µ ======================
    x['model'].half()  # è½¬æ¢ä¸ºFP16

    # è·å–å‚æ•°åˆ—è¡¨ä»¥ç¡®å®šæ€»æ•°
    model_params = list(x['model'].parameters())
    num_params = len(model_params)

    if progress:
        params = tqdm(model_params, desc="ğŸ” ç²¾åº¦è½¬æ¢", unit="param", total=num_params)
    else:
        params = model_params
        print("â–¶ å¼€å§‹ç²¾åº¦è½¬æ¢")

    for p in params:
        p.requires_grad = False

    # ====================== ä¿å­˜é˜¶æ®µ ======================
    save_path = Path(out_model) if out_model else orig_path

    if progress:
        with tqdm(total=1, desc="ğŸ’¾ ä¿å­˜æ¨¡å‹") as save_pbar:
            torch.save(x, save_path)
            save_pbar.update(1)
    else:
        print("â–¶ æ­£åœ¨ä¿å­˜æ¨¡å‹...")
        torch.save(x, save_path)

    # ====================== ç»“æœè¾“å‡º ======================
    new_size = save_path.stat().st_size / 1e6
    print(f"\nâœ… å‹ç¼©å®Œæˆ: {orig_size:.1f}MB â†’ {new_size:.1f}MB (-{100 * (orig_size - new_size) / orig_size:.1f}%)")
    print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {save_path.absolute()}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='ç§»é™¤PyTorchæ¨¡å‹ä¸­çš„ä¼˜åŒ–å™¨ä¿¡æ¯å¹¶å‹ç¼©æ¨¡å‹å¤§å°')
    parser.add_argument('--input', type=str, default='best.pt', help='è¾“å…¥æ¨¡å‹è·¯å¾„')
    parser.add_argument('--output', type=str, default='out.pt', help='è¾“å‡ºè·¯å¾„ï¼ˆç•™ç©ºåˆ™è¦†ç›–è¾“å…¥æ–‡ä»¶ï¼‰')
    parser.add_argument('--progress', type=int, default= False, help='æ˜¾ç¤ºè¿›åº¦æ¡')

    args = parser.parse_args()

    print(f"ğŸš€ å¼€å§‹å¤„ç†: {args.input}")
    #strip_optimizer(input_model=args.input, out_model=args.output)
    strip_optimizer_visualization(input_model=args.input, out_model=args.output, progress=args.progress)